name: Python Webscraping Workflow

on:
  schedule:
    - cron: '10 20 * * *'  # This runs the job every day at midnight (UTC)
  # Optional: Allows you to trigger manually
  workflow_dispatch:


jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    # Checkout the repository
    - name: Checkout repository
      uses: actions/checkout@v2

    # Set up Python
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'  # You can specify the version of Python you want

    # Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    # Run the Python script
    - name: Run scrape_data.py
      run: python scrape_data.py

    # Commit the output file to the repository (optional)
    - name: Commit and push scraped links
      run: |
        git config --global user.name 'github-actions'
        git config --global user.email 'github-actions@github.com'
        git add scraped_links.txt
        git commit -m "Add scraped links"
        git push
 # Trigger the workflow on a cron schedule (every day at midnight)
