name: Python Webscraping Workflow
on:
  # Trigger the workflow on a cron schedule (every day at midnight)
  schedule:
    - cron: '3 20 * * *'  # This runs the job every day at midnight (UTC)
  # Optional: Allows you to trigger manually
  workflow_dispatch:

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4

    - name: Run scraping script
      run: |
        python scrape.py  # Replace with the actual path to your script

    - name: Commit and push scraped links
      run: |
        git config --global user.name 'github-actions'
        git config --global user.email 'github-actions@github.com'
        git add scraped_links.txt
        git commit -m "Add scraped links"
        git push https://x-access-token:${{ secrets.MY_GITHUB_TOKEN }}@github.com/${{ github.repository }}.git
